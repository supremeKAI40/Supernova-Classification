# -*- coding: utf-8 -*-
"""Supernova Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q7LMfw0MR1YC0aAr1t9Hu7LJgPAy2-P5

#Data Import
"""

import pandas as pd
import numpy as np
import matplotlib 
import matplotlib.pyplot as plt
import seaborn as sns

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F

from torchvision.datasets import ImageFolder #to load data from folder
from torch.utils.data import DataLoader 
import torchvision.transforms as tt #to tansform image into tensors
from torch.utils.data import random_split,DataLoader, TensorDataset #for spliting dataset into train and validation set
from torchvision.utils import make_grid

DATA_FILENAME='/content/GSOC_Data_DataCube.txt'

dataset_raw = pd.read_csv(DATA_FILENAME, delimiter=' ', header = None)
#Columns from the information in documents
columns=['depth', 'delta_depth', 'velocity', 'delta_velocity','flux', 'mass','NickelMass', 'Energy', 'flag_mass',"radial_flag"]
dataset_raw.columns= columns

"""#EDA and Visualisation

We already have some knowledge about the datasets from the documentations but it is always a good practice to visualise the data
"""

data=dataset_raw.copy()

#Checking the type of Data present in Dataset
data.dtypes

#From  the knowledge of Observed and Physical Parameters(from Simulation in the given data)
in_cols= columns[0:5]
out_numcols= columns[5:8]
out_txtcols= columns[8:10]

"""From what I infer from the data, we have 3 observable parameters and with the uncertainty in observation. There are 5 physical parameters out of which 2 are Initial Parameter categories and 3 are numerical parameters simulated using the said parameters.

## Input Columns Visualisation

Checking the Distribution of Observed Parameters
"""

fig, axes = plt.subplots(nrows=len(in_cols),  figsize=(10,20))
for i in range(len(in_cols)):
    feature = in_cols[i]
    plt.figure(figsize = (5, 5))
    sns.histplot(x=data[feature].dropna(), ax=axes[i])

fig, ax = plt.subplots(len(in_cols), figsize=(10,15))
for i in range(len(in_cols)):
    ax[i].plot(data[in_cols[i]])
    ax[i].title.set_text(in_cols[i])

"""We can see that almost all the variables are continuous and evenly distributed. 
One remarkable visual inference from this is that Supernova Emergent Flux is surely showing some pattern, which might be attributed to either the types of supernovae being observed or the specific measurement techniques.

## Output Column Visualisation

Checking the distrubution and trends in the physical parameters here,
"""

fig, axes = plt.subplots(nrows=len(out_numcols),ncols=2,figsize=(10,20))
for i in range(len(out_numcols)):
    feature = out_numcols[i]
    plt.figure(figsize = (5, 5))
    sns.histplot(x=data[feature].dropna(), ax=axes[i][0])
    sns.countplot(x=data[feature].dropna(), ax=axes[i][1])

"""*   We can conclude that the physical parameters in the dataset is fairly distributed which actually does indicate towards simulation. 
*   I have plotted the numerical parameters and we can see there are specifically some numerical values and that too very evenly distributed. Out of 512 instances, we can see distribution among output parameters

The distribution of these parameters calls for close inspection.
"""

fig, ax = plt.subplots(len(out_numcols), figsize=(10,15))
plot_base=np.arange(512)
for i in range(len(out_numcols)):
    if(i<2):
        ax[i].plot(data[out_numcols[i]][0:128])
        ax[i].plot(data[out_numcols[i]][128:256])
        ax[i].plot(data[out_numcols[i]][256:384])
        ax[i].plot(data[out_numcols[i]][384:512])
        ax[i].title.set_text(out_numcols[i])
    if (i==2):
        ax[i]=plt.scatter(plot_base[0:36], data[out_numcols[i]][0:36])

"""These Plots show Mass and Nickel Mass show are very related trend and Explosion Energy have only two values 0.75 and 2.0 (units=10^51 ergs)

Plotting the countplot for Initial Parameters of the simulation.
"""

fig, axes = plt.subplots(nrows=len(out_txtcols),figsize=(10,20))
for i in range(len(out_txtcols)):
    feature = out_txtcols[i]
    plt.figure(figsize = (5, 5))
    sns.countplot(x=data[feature].dropna(), ax=axes[i])

"""We can see, initial parameters are of 4 kinds, which has been used to simulate the physical parameters.

## Feature Analysis
"""

Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
lower_range= Q1-(1.5 * IQR)
upper_range= Q3+(1.5 * IQR)
print('Number of Outliers (Percentage):')
((data < (lower_range)) | (data > (upper_range))).sum()/len(data) * 100

"""Now, we already know the data is very specific and streamlined. Plotting a correlation matrix can help us to understand dependancies."""

plt.figure(figsize = (14, 10))
corr_mat = data.corr()
sns.heatmap(corr_mat, xticklabels = corr_mat.columns, yticklabels = corr_mat.columns, annot=True)

"""One of the major takeaways from this is, we can ignore the co-dependencies of one physical parameters on other. 

Although Mass and Nickel Mass are still indeed quite evidently affecting each other.

One of the major techniques to identify the trends of input and output variables is plotting Pairplots.
"""

g = sns.pairplot(data,hue="mass",height=4)
plt.show()

"""To derive relationships of Physical Parameters to Observables, we can plot particular pairplots."""

g = sns.pairplot(data,hue="mass",palette='viridis',x_vars=["depth", "delta_depth", "velocity", "delta_velocity", "flux"],
    y_vars=["mass", "NickelMass","Energy"], height=4)
plt.show()

g1 = sns.pairplot(data,hue="NickelMass",x_vars=["depth", "delta_depth", "velocity", "delta_velocity", "flux"],
    y_vars=["mass", "NickelMass","Energy"],palette='viridis',height=3.5)
plt.show()

g2 = sns.pairplot(data,hue="Energy",x_vars=["depth", "delta_depth", "velocity", "delta_velocity", "flux"],
    y_vars=["mass", "NickelMass","Energy"],palette='viridis', height=3.5)
plt.show()

"""What I will be employing for this particular task is two separate strategies:


1.   We can take advantage of independence of output features and apply separate models for each output parameters as a Regresssion Problem.
2.   We have also seen the Physical Parameters in this dataset is simulated and thus has some particular values only. We can do One-Hot Encoding and treat this as a classification problem. 


I will be applying the first approach, as that model will be more tolerant to real world physical parameter calculations, in my opinion. 

Now, since the number of Instances is only 512, we have to rely on ensemble learning as our primary weapon for predictions, all other models would be prone to bias due to small dataset and might not even understand the underlying patterns.

#Data Split
"""

dataset= dataset_raw.copy()

num_cols= dataset.columns
num_colslen= len(dataset.columns)

input_cols = num_cols[0:5]
print(input_cols)

output_cols = num_cols[5:]
print(output_cols)

categorical_cols = num_cols[8:]
print(categorical_cols)

"""## Normalise Pandas"""

from sklearn.preprocessing import StandardScaler, MinMaxScaler,MaxAbsScaler

dataMinMax= data.copy()

autoscaler = MinMaxScaler()
dataMinMax[in_cols] = autoscaler.fit_transform(dataMinMax[in_cols])

fig, axes = plt.subplots(nrows=len(in_cols),  figsize=(10,20))
for i in range(len(in_cols)):
    feature = in_cols[i]
    plt.figure(figsize = (5, 5))
    sns.histplot(x=dataMinMax[feature].dropna(), ax=axes[i])

"""# Pandas to Tensors"""

def dataframe_to_arrays(dataframe):
    dataframe1 = dataframe.copy(deep=True)
    for col in categorical_cols:
        dataframe1[col] = dataframe1[col].astype('category').cat.codes
    # Extract input & outupts as numpy arrays
    inputs_array = dataframe1[input_cols].to_numpy()
    targets_array = dataframe1[output_cols].to_numpy()
    return inputs_array, targets_array

inputs_array, targets_array = dataframe_to_arrays(dataset)
inputs_array, targets_array

inputs = torch.tensor(inputs_array, dtype= torch.float32)
targets = torch.tensor(targets_array, dtype=torch.float32)

"""#Separate Single Variable Splits"""

targets.size()

mass=targets[:,0]
NiMass= targets[:,1]
Energy= targets[:,2]
massDist= targets[:,3]
radialDist= targets[:,4]

#Changing Classification type tensors to long
massDistLong= massDist.type(torch.LongTensor)
radDistLong= radialDist.type(torch.LongTensor)

datasetMass = TensorDataset(inputs, mass)
datasetNiM = TensorDataset(inputs, NiMass)
datasetNRG= TensorDataset(inputs, Energy)
datasetMassD= TensorDataset(inputs, massDistLong)
datasetRadD= TensorDataset(inputs, radDistLong)

"""#DataLoader batch split"""

num_rows= len(dataset)

val_percent = 0.15 # between 0.1 and 0.2
val_size = int(num_rows * val_percent)
origin_size = num_rows - val_size

train_dsMassO, val_dsMass = random_split(datasetMass,[origin_size,val_size]) 
train_dsNiMO, val_dsNiM = random_split(datasetNiM,[origin_size,val_size])
train_dsNRGO, val_dsNRG = random_split(datasetNRG,[origin_size,val_size])
train_dsMassDO, val_dsMassD = random_split(datasetMassD,[origin_size,val_size])
train_dsRadDO, val_dsRadD = random_split(datasetRadD,[origin_size,val_size])

num_trainRows= len(train_dsMassO)
print(num_trainRows)

test_percent = 0.11
test_size = int(num_trainRows*test_percent)
train_size= num_trainRows- test_size


train_dsMass, test_dsMass = random_split(train_dsMassO,[train_size,test_size]) 
train_dsNiM, test_dsNiM = random_split(train_dsNiMO,[train_size,test_size])
train_dsNRG, test_dsNRG = random_split(train_dsNRGO,[train_size,test_size])
train_dsMassD, test_dsMassD = random_split(train_dsMassDO,[train_size,test_size])
train_dsRadD, test_dsRadD = random_split(train_dsRadDO,[train_size,test_size])

print(len(test_dsMass))

"""#Batch Assignment"""

batch_size = 64

train_loaderMass = DataLoader(train_dsMass, batch_size, shuffle=True)
val_loaderMass = DataLoader(val_dsMass, batch_size)
test_loaderMass = DataLoader(test_dsMass)

train_loaderNiM = DataLoader(train_dsNiM, batch_size, shuffle=True)
val_loaderNiM = DataLoader(val_dsNiM, batch_size)
test_loaderNiM = DataLoader(test_dsNiM)

train_loaderNRG = DataLoader(train_dsNRG, batch_size, shuffle=True)
val_loaderNRG = DataLoader(val_dsNRG, batch_size)
test_loaderNRG = DataLoader(test_dsNRG)

train_loaderMassD = DataLoader(train_dsMassD, batch_size, shuffle=True)
val_loaderMassD = DataLoader(val_dsMassD, batch_size)
test_loaderMassD = DataLoader(test_dsMassD)

train_loaderRadD = DataLoader(train_dsRadD, batch_size, shuffle=True)
val_loaderRadD = DataLoader(val_dsRadD, batch_size)
test_loaderRadD = DataLoader(test_dsRadD)

for xb, yb in train_loaderMass:
    print("inputs:", xb)
    print("targets:", yb.unsqueeze(0))
    break

"""After application of various other Regression Techniques. Two of the best performance was achieved by Stacking Regressor and Linar Regression Neural Network Model in PyTorch. 

The Advantage of Pytorch is that we get greater control of over model. 

And It would help us debug cases when there is overfitting of Data

# Model Class
"""

input_size = len(input_cols)
hidden_size= 3
output_size = 1

class RegressionModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.lossFn = torch.nn.MSELoss()
        #use input_size & output_size defined above
        # hidden layer
        self.linear1 = nn.Linear(input_size, hidden_size)
        # output layer
        self.linear2 = nn.Linear(hidden_size, output_size)

    def forward(self, xb):
        #xb = xb.squeeze(0)
        out = self.linear1(xb) 
        # Apply activation function
        out1 = F.relu(out)
        # Get predictions using output layer
        out1 = self.linear2(out1)                        
        return out1
    
    def training_step(self, batch):
        inputs, targets = batch 
        targets= targets.unsqueeze(-1)
        # Generate predictions
        out = self(inputs)          
        # Calcuate loss
        loss = self.lossFn(out,targets)                    
        return loss
    
    def validation_step(self, batch):
        inputs, targets = batch
        targets= targets.unsqueeze(-1)
        # Generate predictions
        out = self(inputs)
        # Calculate loss
        loss = self.lossFn(out,targets)                          
        return {'val_loss': loss.detach()}
        
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        return {'val_loss': epoch_loss.item()}
    
    def epoch_end(self, epoch, result, num_epochs):
        # Print result every 20th epoch
        if (epoch+1) % 5== 0 or epoch == num_epochs-1:
            print("Epoch [{}],train_loss: {:.4f}, val_loss: {:.4f}".format(epoch+1,result['train_loss'], result['val_loss']))

"""#Model Init"""

modelMass= RegressionModel()

modelNiM= RegressionModel()
modelNRG= RegressionModel()

list(modelMass.parameters())

"""#Training Helper functions"""

def evaluate(model, val_loader):
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):
    history = []
    train_losses = []
    optimizer = opt_func(model.parameters(), lr)
    for epoch in range(epochs):
        # Training Phase 
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        model.epoch_end(epoch, result, epochs)
        history.append(result)
    return history

"""#Training and Propagation

## Mass
"""

result = evaluate(modelMass, val_loaderMass) # Use the the evaluate function
print(result)

epochs = 64
lr = 1e-5
history1 = fit(epochs, lr, modelMass, train_loaderMass, val_loaderMass)

epochs = 64
lr = 1e-5
history1 += fit(epochs, lr, modelMass, train_loaderMass, val_loaderMass)

epochs = 64
lr = 1e-4
history1 += fit(epochs, lr, modelMass, train_loaderMass, val_loaderMass)

epochs = 64
lr = 1e-4
history1 += fit(epochs, lr, modelMass, train_loaderMass, val_loaderMass)

epochs = 100
lr = 1e-4
history1 += fit(epochs, lr, modelMass, train_loaderMass, val_loaderMass)

def plot_losses(history):
    train_losses = [x.get('train_loss') for x in history]
    val_losses = [x['val_loss'] for x in history]
    plt.plot(train_losses, '-bx')
    plt.plot(val_losses, '-rx')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend(['Training', 'Validation'])
    plt.title('Loss vs. No. of epochs');

plot_losses(history1)

"""###Testing Mass Values"""

test1=torch.FloatTensor([3.35,0,0.015,0,1.20e-5])

yb= modelMass(test1)
print(yb)

test2= torch.FloatTensor([2.54,0,0.013,0,5.02e-6])
test3= torch.FloatTensor([2.46,0,0.013,0, 1.03e-5])

yb2= modelMass(test2)
yb3= modelMass(test3)
print(yb2)

resultTest= evaluate(modelMass, test_loaderMass) # Use the the evaluate function
print(resultTest)

"""## Nickel Mass"""

resultNiM = evaluate(modelNiM, val_loaderNiM) # Use the the evaluate function
print(resultNiM)

epochs = 50
lr = 1e-6
history1 += fit(epochs, lr, modelNiM, train_loaderNiM, val_loaderNiM)

epochs = 50
lr = 1e-4
history1 += fit(epochs, lr, modelNiM, train_loaderNiM, val_loaderNiM)

plot_losses(history1)

"""### Testing Nickel Mass Values"""

yb11= modelNiM(test1)
yb22= modelNiM(test2)
yb33= modelNiM(test3)
print(yb11,yb22,yb33)

resultTestNiM= evaluate(modelNiM, test_loaderNiM) # Use the the evaluate function
print(resultTestNiM)

"""## Energy"""

result = evaluate(modelNRG, val_loaderNRG) # Use the the evaluate function
print(result)

epochs = 50
lr = 1e-4
history1 = fit(epochs, lr, modelNRG, train_loaderNRG, val_loaderNRG)

epochs = 50
lr = 1e-4
history1 += fit(epochs, lr, modelNRG, train_loaderNRG, val_loaderNRG)

epochs = 50
lr = 1e-4
history1 += fit(epochs, lr, modelNRG, train_loaderNRG, val_loaderNRG)

epochs = 64
lr = 1e-4
history1 += fit(epochs, lr, modelNRG, train_loaderNRG, val_loaderNRG)

epochs = 100
lr = 1e-5
history1 += fit(epochs, lr, modelNRG, train_loaderNRG, val_loaderNRG)

"""### Testing Energy Values"""

resultTestNRG= evaluate(modelNRG, test_loaderNRG) # Use the the evaluate function
print(resultTestNRG)

yb11= modelNRG(test1)
yb22= modelNRG(test2)
yb33= modelNRG(test3)
print(yb11,yb22,yb33)

"""We have achieved fairly good results for the 3 Numeric Outputs, we are required to predict.

Keeping in mind the dataset is very small for now. I have ignored use of some of the training techniques especially the use of Weight Decay and Gradient Clipping which helps to punish outliers in model. 

Now with these results in mind, we can proceed to attempt Pytorch Classification Models on last two columns which are basically categorical in nature for Inital Parameters

#Classification of Last 2 Columns

## Pytorch Classification Linear Networks

###Model Class

#### Training Helper and Accuracy for Classification
"""

def accuracy(outputs, targets):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == targets).item() / len(preds))

class ClassificationModel(nn.Module):
    """Feedfoward neural network with 1 hidden layer"""
    def __init__(self, in_size, hidden_size, out_size):
        super().__init__()
        # hidden layer
        self.linear1 = nn.Linear(in_size, hidden_size)
        # output layer
        self.linear2 = nn.Linear(hidden_size, out_size)
        
    def forward(self, xb):
        #xb = xb.squeeze(0)
        out = self.linear1(xb) 
        # Apply activation function
        out1 = F.relu(out)
        # Get predictions using output layer
        #out1 = self.linear2(out1)                        
        return out1
    
    def training_step(self, batch):
        inputs, targets = batch 
        #targets= targets.unsqueeze(-1)
        out = self(inputs)                  # Generate predictions
        loss = F.cross_entropy(out, targets) # Calculate loss
        return loss
    
    def validation_step(self, batch):
        inputs, targets = batch 
        out = self(inputs)                    # Generate predictions
        loss = F.cross_entropy(out, targets)   # Calculate loss
        acc = accuracy(out, targets)           # Calculate accuracy
        return {'val_loss': loss, 'val_acc': acc}
        
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}
    
    def epoch_end(self, epoch, result):
        print("Epoch [{}], val_loss: {:.6f}, val_acc: {:.6f}".format(epoch, result['val_loss'], result['val_acc']))

def evaluateC(model, val_loader):
    """Evaluate the model's performance on the validation set"""
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def fitC(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):
    """Train the model using gradient descent"""
    history = []
    optimizer = opt_func(model.parameters(), lr)
    for epoch in range(epochs):
        # Training Phase 
        for batch in train_loader:
            loss = model.training_step(batch)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        model.epoch_end(epoch, result)
        history.append(result)
    return history

"""###Model Init"""

modelMassD= ClassificationModel(input_size,4, 4)
modelRadD= ClassificationModel(input_size,4, 4)

"""### Mass Distribution
4 Categories

#### Training
"""

history = [evaluateC(modelMassD, val_loaderMassD)]
history

history += fitC(5, 0.5, modelMassD, train_loaderMassD, val_loaderMassD)

history += fitC(50, 0.005, modelMassD, train_loaderMassD, val_loaderMassD)

history += fitC(50, 0.0005, modelMassD, train_loaderMassD, val_loaderMassD)

plot_losses(history)

"""## ML Classifier Algorithms

It is visible the loss is getting saturated in Linear and Neural Network Models.

I also employed Decision Tree, Random Forest Models for classification, KNeighbours, etc for classification. Again the best results are obtained for Ensemble

Best Result is obtained in classification with Ensemble Learning. Applying AdaBoost, Stacking and Voting Classifiers performed better.

But Here I am mentioning the best results in terms of performance on a custom test set already separated.

A further probe can be undertaken for better Neural Networks
"""

#Import Dependancies
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression,RidgeClassifier
from sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier, DecisionTreeRegressor, ExtraTreeRegressor
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, StackingClassifier, VotingClassifier, RandomForestRegressor,VotingRegressor, StackingRegressor
ExtraTreeRegressor
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, plot_confusion_matrix

physical_parameters=['mass', 'NickelMass','Energy','flag_mass','radial_flag']
dataMinMax1= dataMinMax.copy()

"""### Mass Distribution"""

x4MinMax= dataMinMax1[dataMinMax.columns[0:5]]
y4MinMax=dataMinMax1['flag_mass']
print(x4MinMax, y4MinMax)

x_train4MinMax, x_test4MinMax, y_train4MinMax, y_test4MinMax = train_test_split(x4MinMax, y4MinMax, test_size=0.2, random_state=42)
x_val4MinMax, x_test4MinMax, y_val4MinMax, y_test4MinMax = train_test_split(x_test4MinMax, y_test4MinMax, test_size=0.5, random_state=42)
print(x_train4MinMax.shape)
print(x_val4MinMax.shape)
print(x_test4MinMax.shape)
print(y_train4MinMax.shape)
print(y_val4MinMax.shape)
print(y_test4MinMax.shape)

dtflagmass= DecisionTreeClassifier(max_depth=4)
dtflagmass.fit(x_train4MinMax, y_train4MinMax)
y_pred4MinMax = dtflagmass.predict(x_val4MinMax)
print(classification_report(y_pred4MinMax,y_val4MinMax))

randomflagmass= RandomForestClassifier(max_depth=30)
randomflagmass.fit(x_train4MinMax, y_train4MinMax)
y_pred4MinMax = randomflagmass.predict(x_val4MinMax)
print(classification_report(y_pred4MinMax,y_val4MinMax))

y_testing= randomflagmass.predict(x_test4MinMax)
print(classification_report(y_testing,y_test4MinMax))

"""Although Classification is still not very good, but we can see a considerable improvement from Neural Network or Linear Regression type models.

Thus I would be using Stacking Classifier with base estimator as our Random Forest Classifier
"""

est = RandomForestClassifier()

estimators = [('lr',LogisticRegression()),
              ('rc',RidgeClassifier()),
              ('et',ExtraTreeClassifier()),
              ('dt',DecisionTreeClassifier()),
              ('rf',RandomForestClassifier()),
              ('ab',AdaBoostClassifier()),
              ('bc',BaggingClassifier())]
stack4 = StackingClassifier(estimators=estimators, final_estimator=est)
stack4.fit(x_train4MinMax, y_train4MinMax)
y_pred4MinMax = stack4.predict(x_val4MinMax)
print(accuracy_score(y_val4MinMax, y_pred4MinMax))
print(classification_report(y_val4MinMax, y_pred4MinMax))

# Plot the confusion matrix using the provided functions.
plot_confusion_matrix(stack4, x_val4MinMax, y_val4MinMax)  
plt.show()

"""###Final Test of Mass Distribution Parameters"""

y_testing= stack4.predict(x_test4MinMax)
print(classification_report(y_testing,y_test4MinMax))

y_test111= stack4.predict(test1.reshape(-1,5))
y_test222= stack4.predict(test2.reshape(-1,5))
y_test333= stack4.predict(test3.reshape(-1,5))
print(y_test111,y_test222,y_test333)

"""### Radial Ni Distribution"""

x5MinMax= dataMinMax1[dataMinMax.columns[0:5]]
y5MinMax=dataMinMax1['radial_flag']
print(x5MinMax, y5MinMax)

x_train5MinMax, x_test5MinMax, y_train5MinMax, y_test5MinMax = train_test_split(x5MinMax, y5MinMax, test_size=0.2, random_state=42)
x_val5MinMax, x_test5MinMax, y_val5MinMax, y_test5MinMax = train_test_split(x_test5MinMax, y_test5MinMax, test_size=0.5, random_state=42)
print(x_train5MinMax.shape)
print(x_val5MinMax.shape)
print(x_test5MinMax.shape)
print(y_train5MinMax.shape)
print(y_val5MinMax.shape)
print(y_test5MinMax.shape)

randomflagrad= RandomForestClassifier(max_depth=11)
randomflagrad.fit(x_train5MinMax, y_train5MinMax)
y_pred5MinMax = randomflagrad.predict(x_val5MinMax)
print(classification_report(y_pred5MinMax,y_val5MinMax))

y_testrand= randomflagrad.predict(x_test5MinMax)
print(classification_report(y_testrand,y_test5MinMax))

est = RandomForestClassifier()

estimators = [('lr',LogisticRegression()),
              ('rc',RidgeClassifier()),
              ('et',ExtraTreeClassifier()),
              ('dt',DecisionTreeClassifier()),
              ('rf',RandomForestClassifier()),
              ('ab',AdaBoostClassifier()),
              ('bc',BaggingClassifier())]
stack5 = StackingClassifier(estimators=estimators, final_estimator=est)
stack5.fit(x_train5MinMax, y_train5MinMax)
y_pred5MinMax = stack5.predict(x_val5MinMax)
print(accuracy_score(y_val5MinMax, y_pred5MinMax))
print(classification_report(y_val5MinMax, y_pred5MinMax))

# Plot the confusion matrix using the provided functions.
plot_confusion_matrix(stack5, x_val5MinMax, y_val5MinMax)  
plt.show()

"""###Final Test of Nickel Mass Distribution Parameters"""

y_testing= stack5.predict(x_test5MinMax)
print(classification_report(y_testing,y_test5MinMax))

y_test11= stack5.predict(test1.reshape(-1,5))
y_test22= stack5.predict(test2.reshape(-1,5))
y_test33= stack5.predict(test3.reshape(-1,5))
print(y_test11,y_test22,y_test33)

"""Although my Model can be used to predict the values with fair efficiency, I would certainly try to implement Boosting Algorithms apart from Ensemble Learning. 

I have not applied Boosting Models to their optimum due to the small dataset here, but it can provide that extra step in accuracy. 
"""